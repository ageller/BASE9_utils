{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Random Forest model from BASE-9 data\n",
    "\n",
    "\n",
    "This notebook performs the following tasks:\n",
    "- reads in posterior data from BASE-9\n",
    "- generates features from these data \n",
    "- uses these features to train and test a random forest classifier from `scipy`\n",
    "- and saves the model to a file.  \n",
    "\n",
    "Here we use data from NGC 2682 (M67) to train the model; these data were hand labelled by Justyce.  If you need access to these data, please contact Aaron Geller.\n",
    "\n",
    "Most of the \"heavy lifting\" is done by the code in the `base9_ml_utils.py` file.  See the comments and markdown in that code for more details.\n",
    "\n",
    "\n",
    "___\n",
    "*Authors:* Justyce Watson, Aaron Geller\\\n",
    "*Date:* August 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all functions from the `base9_ml_utils.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from .py file\n",
    "from base9_ml_utils import *\n",
    "\n",
    "# The lines below are useful if you plan to make changes to the base9_ml_utils.py file.\n",
    "# They will allow the notebook to refresh when you save changes to the .py file.\n",
    "#\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in `.res` files and creates the features \n",
    "\n",
    "The user should specify the data directory on their own computer.  The code assumes that this directory contains one `.res` file for each star with the filename containing the star ID.  (If there is additional text in the file name, the user can specify this in the code, using the `file_prefix` and/or `file_suffix` args so that the code can identify the star ID from the filename properly.)  \n",
    "\n",
    "We will use the `create_features` function imported from `base9_ml_utils.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mcreate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_nfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfile_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NGC_2682_'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfile_suffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mess_num_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "function that will calculate all the features needed for the ML model \n",
      "Note that the file names for the res files must contain the ids (and can include a prefix and suffix)\n",
      "\n",
      "inputs:\n",
      "- directory : (string) path to the data directory that contains the res files from BASE-9\n",
      "- column : (string) column number to use from the res file to use to calculate features\n",
      "- max_nfiles : (int) maximum number of files to use\n",
      "- file_prefix : (string) prefix in the res file names before the id \n",
      "- file_suffix : (string) suffix in the res file names after the id\n",
      "- ess_num_samples : (int) number of samples to use in ess normal distribution\n",
      "\n",
      "outputs:\n",
      "- pandas DataFrame with the calculated features (see code for more details)\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Desktop/CIERA_files/BASE9_ML/BASE9_ML-1/base9_ml_utils.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "# run this cell to see information about this function\n",
    "create_features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>Width</th>\n",
       "      <th>Upper_bound</th>\n",
       "      <th>Lower_bound</th>\n",
       "      <th>Stdev</th>\n",
       "      <th>SnR</th>\n",
       "      <th>Dip_p</th>\n",
       "      <th>Dip_value</th>\n",
       "      <th>KS_value</th>\n",
       "      <th>KS_p</th>\n",
       "      <th>ESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605002016872204416</td>\n",
       "      <td>1.361236</td>\n",
       "      <td>0.557799</td>\n",
       "      <td>0.967022</td>\n",
       "      <td>0.658567</td>\n",
       "      <td>14.214572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>0.225703</td>\n",
       "      <td>3.966666e-279</td>\n",
       "      <td>9914.081693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>604942879467199360</td>\n",
       "      <td>1.352529</td>\n",
       "      <td>0.557799</td>\n",
       "      <td>0.967022</td>\n",
       "      <td>0.610061</td>\n",
       "      <td>15.058561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.152922</td>\n",
       "      <td>1.644700e-124</td>\n",
       "      <td>10164.999869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>604969031523465728</td>\n",
       "      <td>0.387865</td>\n",
       "      <td>0.557799</td>\n",
       "      <td>0.967022</td>\n",
       "      <td>0.263017</td>\n",
       "      <td>36.229304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.155823</td>\n",
       "      <td>1.805514e-132</td>\n",
       "      <td>10070.746059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604921679508385664</td>\n",
       "      <td>1.676418</td>\n",
       "      <td>0.557799</td>\n",
       "      <td>0.967022</td>\n",
       "      <td>0.744099</td>\n",
       "      <td>12.044454</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.141053</td>\n",
       "      <td>1.188060e-107</td>\n",
       "      <td>9933.271378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>604968958508607360</td>\n",
       "      <td>1.262185</td>\n",
       "      <td>0.557799</td>\n",
       "      <td>0.967022</td>\n",
       "      <td>0.600071</td>\n",
       "      <td>15.298958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014429</td>\n",
       "      <td>0.130290</td>\n",
       "      <td>1.232158e-89</td>\n",
       "      <td>10006.607425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>604994045412975744</td>\n",
       "      <td>0.770949</td>\n",
       "      <td>0.557799</td>\n",
       "      <td>0.967022</td>\n",
       "      <td>0.473367</td>\n",
       "      <td>19.784625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>0.166776</td>\n",
       "      <td>2.267155e-149</td>\n",
       "      <td>9908.144625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>604921924322164608</td>\n",
       "      <td>0.167193</td>\n",
       "      <td>0.557799</td>\n",
       "      <td>0.967022</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>105.613775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012850</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>9.241779e-126</td>\n",
       "      <td>9671.638661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>604970062315630336</td>\n",
       "      <td>1.360707</td>\n",
       "      <td>0.557799</td>\n",
       "      <td>0.967022</td>\n",
       "      <td>0.639646</td>\n",
       "      <td>14.251756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013919</td>\n",
       "      <td>0.153942</td>\n",
       "      <td>3.812003e-125</td>\n",
       "      <td>9850.930115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>598962292125778560</td>\n",
       "      <td>1.532101</td>\n",
       "      <td>0.557799</td>\n",
       "      <td>0.967022</td>\n",
       "      <td>0.686447</td>\n",
       "      <td>13.055923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>0.125103</td>\n",
       "      <td>2.478370e-83</td>\n",
       "      <td>9630.701794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>597810107020313344</td>\n",
       "      <td>1.524821</td>\n",
       "      <td>0.557799</td>\n",
       "      <td>0.967022</td>\n",
       "      <td>0.690170</td>\n",
       "      <td>13.100619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029765</td>\n",
       "      <td>0.163485</td>\n",
       "      <td>3.499865e-141</td>\n",
       "      <td>9886.586582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1427 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               source_id     Width  Upper_bound  Lower_bound     Stdev  \\\n",
       "0     605002016872204416  1.361236     0.557799     0.967022  0.658567   \n",
       "1     604942879467199360  1.352529     0.557799     0.967022  0.610061   \n",
       "2     604969031523465728  0.387865     0.557799     0.967022  0.263017   \n",
       "3     604921679508385664  1.676418     0.557799     0.967022  0.744099   \n",
       "4     604968958508607360  1.262185     0.557799     0.967022  0.600071   \n",
       "...                  ...       ...          ...          ...       ...   \n",
       "1423  604994045412975744  0.770949     0.557799     0.967022  0.473367   \n",
       "1424  604921924322164608  0.167193     0.557799     0.967022  0.091203   \n",
       "1425  604970062315630336  1.360707     0.557799     0.967022  0.639646   \n",
       "1426  598962292125778560  1.532101     0.557799     0.967022  0.686447   \n",
       "1427  597810107020313344  1.524821     0.557799     0.967022  0.690170   \n",
       "\n",
       "             SnR     Dip_p  Dip_value  KS_value           KS_p           ESS  \n",
       "0      14.214572  0.000000   0.017193  0.225703  3.966666e-279   9914.081693  \n",
       "1      15.058561  0.000000   0.019429  0.152922  1.644700e-124  10164.999869  \n",
       "2      36.229304  0.000000   0.012712  0.155823  1.805514e-132  10070.746059  \n",
       "3      12.044454  0.000001   0.008560  0.141053  1.188060e-107   9933.271378  \n",
       "4      15.298958  0.000000   0.014429  0.130290   1.232158e-89  10006.607425  \n",
       "...          ...       ...        ...       ...            ...           ...  \n",
       "1423   19.784625  0.000000   0.009089  0.166776  2.267155e-149   9908.144625  \n",
       "1424  105.613775  0.000000   0.012850  0.153061  9.241779e-126   9671.638661  \n",
       "1425   14.251756  0.000000   0.013919  0.153942  3.812003e-125   9850.930115  \n",
       "1426   13.055923  0.000000   0.020750  0.125103   2.478370e-83   9630.701794  \n",
       "1427   13.100619  0.000000   0.029765  0.163485  3.499865e-141   9886.586582  \n",
       "\n",
       "[1427 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directory on your computer where the .res data files are stored\n",
    "directory = \"data/NGC2682/jw_output\"\n",
    "\n",
    "# create a DataFrame with features for each star using the 'create_features'\n",
    "model_cluster_statistic = create_features(directory)\n",
    " \n",
    "# display the resulting DataFrame in the notebook\n",
    "model_cluster_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data for training and testing the model\n",
    "\n",
    "This dataset contains hand labelled sampling quality for each star that has a `.res` file in the dataset above.  The labels were created by Justyce Watson by visually inspecting the distributions in the `.res` files.\n",
    "\n",
    "In this dataset we will use the column `Single Sampling` as our label, and only take rows where the a label exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>Single Sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>597810107020313344</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>597830722862488064</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>598464900553093504</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>598525408052424960</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>598543206396991232</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>605170688827236736</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>603848521800034176</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>603868141210083712</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>607987427163771520</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>607989355604856192</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1426 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               source_id Single Sampling\n",
       "0     597810107020313344             Bad\n",
       "1     597830722862488064             Bad\n",
       "2     598464900553093504             Bad\n",
       "3     598525408052424960             Bad\n",
       "4     598543206396991232             Bad\n",
       "...                  ...             ...\n",
       "1435  605170688827236736             Bad\n",
       "1436  603848521800034176             Bad\n",
       "1438  603868141210083712             Bad\n",
       "1439  607987427163771520            Good\n",
       "1440  607989355604856192             Bad\n",
       "\n",
       "[1426 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "df1 = pd.read_csv('data/NGC2682/NGC2682_Age_Stats.csv',sep=',')\n",
    "\n",
    "# Select only the rows where Single Sampling values exist\n",
    "# And keep only the relevant columns\n",
    "sampling_df = df1[df1['Single Sampling'].isna() == False][['source_id','Single Sampling']]\n",
    "\n",
    "# Display this DataFrame in the notebook\n",
    "sampling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model \n",
    "Here we use the `create_model` function imported from `base9_ml_utils.py`.  In this function we split the data into training and testing subsets.  The training set is further modified so that there are equal \"Good\" and \"Bad\" labelled data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfeatures_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlabel_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlabel_column_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Single Sampling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Upper_bound'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Lower_bound'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Stdev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SnR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dip_p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dip_value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'KS_value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'KS_p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ESS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "function that will create a random forest model using scikit-learn\n",
      "\n",
      "inputs:\n",
      "- features_df : (pandas DataFrame) contains all the features needed for the model, including an ID column (e.g., from create_features function)\n",
      "- label_df : (pandas DataFrame) contains a label for each id in the features_df to train the model\n",
      "- label_column_name : (string) the name of the column in label_df that has the desired label for training\n",
      "- feature_columns : (list of strings) a list of column names in features_df to use for the model \n",
      "- random_seed : (int) used for test_train_split and RandomForestClassifier\n",
      "\n",
      "outputs:\n",
      "- pipe: scikit-learn pipeline object containing the random forest model and standard scaler\n",
      "- X : (np array) every row is a different star, every column is a feature (same order as y)\n",
      "- y: (np array)  every row is a different star, every column is the label (same order as X)\n",
      "- X_train : (np array) portion of X that was used to train the data\n",
      "- y_train : (np array) portion of y used to train the data\n",
      "- X_test : (np array) portion of X that can be used to test the data (if user desires)\n",
      "- y_test : (np array) portion of y that can be used to test the data\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Desktop/CIERA_files/BASE9_ML/BASE9_ML-1/base9_ml_utils.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "# run this cell to see information about this function\n",
    "create_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 174 training elements with classification = Bad\n",
      "There are 174 training elements with classification = Good\n"
     ]
    }
   ],
   "source": [
    "# create the model (returned as a scipy pipeline object, here we call it \"pipe\")\n",
    "pipe, X, y, X_train, y_train, X_test, y_test = create_model(model_cluster_statistic, sampling_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model to generate labels\n",
    "Here we use the `make_preds` function imported from `base9_ml_utils.py`.  In this function we send the model from `create_model` and data to be labeled.  For this step we will send the testing data.  We will also define the labels for the test data so that we can validate the quality of the model.  (Note that you can use `make_preds` without knowing the labels, as we will do in the `apply_model.ipynb` notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mmake_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Upper_bound'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Lower_bound'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Stdev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SnR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dip_p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dip_value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'KS_value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'KS_p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ESS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "function that uses the model (from create_model) to generate labels on new data\n",
      "this function can alsob e used to test the quality of the model\n",
      "\n",
      "inputs:\n",
      "- pipe : scikit-learn pipeline object containing the random forest model and scaler objects (e.g., generated by create_model)\n",
      "- X : (np array, or pandas DataFrame) contains features to pass to the model.  every row is a different star, every column is a feature (same order as y)\n",
      "  note: if the user passes a DataFrame, it will be converted to numpy array using prepare_df_for_model\n",
      "- y_test : (np array, optional) labels for X (in same order) that can be used to test the model\n",
      "- feature_columns : (list of strings) a list of column names in features_df to use for the model (must be the same as in create_model)\n",
      "\n",
      "outputs:\n",
      "- np array witht he predictions of the model (in same order as X)\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Desktop/CIERA_files/BASE9_ML/BASE9_ML-1/base9_ml_utils.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "# run this cell to see information about this function\n",
    "make_preds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9532710280373832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.99      0.95      0.97       359\n",
      "        Good       0.80      0.96      0.87        69\n",
      "\n",
      "    accuracy                           0.95       428\n",
      "   macro avg       0.89      0.95      0.92       428\n",
      "weighted avg       0.96      0.95      0.95       428\n",
      "\n",
      "Feature Importance Ranking:\n",
      "Width          0.311279\n",
      "Stdev          0.254817\n",
      "SnR            0.234973\n",
      "KS_value       0.110907\n",
      "Dip_value      0.054472\n",
      "ESS            0.025940\n",
      "Dip_p          0.005492\n",
      "KS_p           0.002120\n",
      "Upper_bound    0.000000\n",
      "Lower_bound    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_pred = make_preds(pipe, X_test, y_test=y_test, \n",
    "    feature_columns=[\n",
    "        \"Width\",\n",
    "        \"Upper_bound\",\n",
    "        \"Lower_bound\",\n",
    "        \"Stdev\",\n",
    "        \"SnR\",\n",
    "        \"Dip_p\",\n",
    "        \"Dip_value\",\n",
    "        \"KS_value\",\n",
    "        \"KS_p\",\n",
    "        \"ESS\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "You can then read in your model to apply it to other datasets.  Note that in order to use a saved model, you will need to be working with the same version of scipy (and possibly other dependencies).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(pipe, filename=\"my_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
